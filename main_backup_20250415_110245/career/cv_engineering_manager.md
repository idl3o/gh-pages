# Sarah Chen

**Engineering Manager - AI Infrastructure & Inference Systems**  
[sarah.chen@example.com](mailto:sarah.chen@example.com) | [linkedin.com/in/sarahchen](https://linkedin.com/in/sarahchen) | San Francisco, CA

## Summary

Engineering leader with 12+ years of experience building high-performance distributed systems and ML infrastructure. Specialized in designing and scaling production inference platforms that balance speed, reliability, and cost. Proven track record of leading cross-functional teams to deliver AI solutions that bridge research innovations with production requirements. Skilled at developing technical roadmaps for complex systems while fostering inclusive and high-performing team cultures.

## Professional Experience

### Distributed Systems Technology Inc.
**Senior Engineering Manager, ML Inference Platform** | 2021 - Present
- Lead a team of 20+ engineers building a high-throughput inference system serving 10M+ daily requests with 99.99% reliability
- Architected a dynamic scaling system that reduced inference costs by 47% while maintaining sub-100ms p95 latency
- Implemented efficient model deployment pipelines reducing time-to-production from weeks to hours
- Successfully transitioned 5 research models to production, enabling new product features for 3M+ users
- Collaborated with research teams to optimize transformer models, achieving 3.5x throughput improvement

### BlockStream Technologies
**Engineering Manager, Platform Infrastructure** | 2018 - 2021
- Led distributed systems team focused on real-time data processing and high-performance serving
- Designed and implemented a decentralized content delivery network with intelligent caching systems
- Created smart contract verification systems using formal methods to ensure platform security
- Built micro-service architecture that scaled to handle 50M transactions daily
- Mentored 12 engineers, with 5 promoted to senior roles under my leadership

### TechFrontier Innovations
**Senior Software Engineer, Infrastructure** | 2015 - 2018
- Designed and implemented distributed payment processing system with fault tolerance capabilities
- Developed horizontal scaling mechanisms for real-time data processing, handling 30K events/second
- Built ML-based anomaly detection systems to identify unusual transaction patterns
- Created performance testing frameworks that identified and resolved system bottlenecks

### DataSystems Inc.
**Software Engineer** | 2011 - 2015
- Developed high-performance data indexing and retrieval systems
- Implemented efficient caching layers reducing database load by 65%
- Created analytics pipelines for real-time metrics processing
- Contributed to open-source distributed computing libraries

## Technical Skills

- **Infrastructure & Systems**: Distributed systems, High-performance computing, Kubernetes, Docker, AWS, GCP
- **ML Systems**: TensorFlow Serving, PyTorch, ONNX Runtime, Triton Inference Server, Model optimization
- **Programming**: Python, Go, Rust, C++, Java
- **Data & Databases**: PostgreSQL, Redis, Kafka, Spark, ElasticSearch
- **DevOps & Reliability**: CI/CD, GitOps, Prometheus, Grafana, SRE practices

## Education

**Stanford University**  
M.S. Computer Science, Concentration in Machine Learning | 2009 - 2011

**University College London**  
B.Eng. Computer Science, First Class Honours | 2005 - 2009

## Publications & Talks

- "Scaling Transformer Inference: Lessons from Serving Billions of Requests," MLSys Conference, 2023
- "Dynamic Batching Strategies for Efficient Model Serving," NeurIPS Workshop on ML Systems, 2022
- "Optimizing Cache Coherence Protocols for Distributed ML Inference," OSDI, 2021
- "Building Resilient ML Production Systems," QCon San Francisco, 2020
